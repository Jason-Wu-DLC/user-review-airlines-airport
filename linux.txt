# Update and upgrade the system to ensure all packages are up-to-date
sudo apt update && sudo apt upgrade -y

# Install necessary tools: curl, wget, and git
sudo apt install -y curl wget git

# Install Docker 
sudo apt-get install docker.io -y

# Download and install the specified version of Docker Compose
sudo curl -L "https://github.com/docker/compose/releases/download/1.26.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# Option 1: Clone the project repository from GitHub
git clone https://github.com/yulin-wu-UQ/infs3208bigdata.git
cd infs3208bigdata

# Option 2: Manually set up the project directory and environment
mkdir ~/infs3208bigdata
cd ~/infs3208bigdata
vim docker-compose.yml  # Create and edit the Docker Compose configuration file
vim hadoop.env  # Create and edit the environment configuration file for Hadoop
mkdir nbs/  # Create a directory for notebook files
mkdir raw/  # Create a directory for raw data files

# Important: Set permissions to ensure Docker can access these directories
sudo chmod -R 777 nbs/
sudo chmod -R 777 raw/

# Start up all containers as defined in the Docker Compose configuration
sudo docker-compose up -d

# Check the status of running Docker containers to ensure they are up and running
sudo docker ps

# Upload data files from the local system to the Hadoop Distributed File System (HDFS)
sudo docker exec -it 0e38cfcfc802 hdfs dfs -put /home/nbs/airline.csv /raw/airline.csv 
sudo docker exec -it 0e38cfcfc802 hdfs dfs -put /home/nbs/airport.csv /raw/airport.csv
sudo docker exec -it 0e38cfcfc802 hdfs dfs -put /home/nbs/lounge.csv /raw/lounge.csv 
sudo docker exec -it 0e38cfcfc802 hdfs dfs -put /home/nbs/seat.csv /raw/seat.csv
